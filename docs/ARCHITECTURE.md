# SPAM_BOSS — Архитектура антиспам-системы LifeMart

Этот документ описывает текущую архитектуру многоступенчатой антиспам‑системы, логику принятия решений, процесс обучения моделей и операционные сценарии в Telegram. В конце приведены рекомендации, к какому классу решений мы ближе и как эволюционировать к более сильным embedding‑моделям и/или LLM.

---

## 1. Картина целиком

Ключевая идея — гибрид из быстрых эвристик и статистики (Keyword, TF‑IDF) плюс семантика (эмбеддинги) с контекстом, агрегируемая мета‑классификатором и управляемая Policy Engine.

Поток данных:

```
[Telegram Update]
   ↓
bot/handlers.py — on_message()
   ↓
FilterCoordinator — сбор скорингов + контекстные капсулы (E_msg/E_ctx/E_user)
   ↓
MetaClassifier — единая p_spam с отладочными фичами
   ↓
PolicyEngine — решение (APPROVE/NOTIFY/DELETE/KICK)
   ↓
Модераторская карточка + действия (удаление/бан) + пополнение датасета
   ↓
TF‑IDF авто‑переобучение по порогу добавленных примеров
```

Главные компоненты:
- bot/handlers — интеграция с Telegram (входной поток, уведомления модератору).
- core/coordinator — оркестрация фильтров, сбор истории чата/пользователя, формирование капсул контекста и пакетных эмбеддингов.
- filters/* — отдельные фильтры: Keyword, TF‑IDF, Embedding.
- services/meta_classifier — мета‑классификатор (LogReg+калибровка) на фичах из эмбеддингов, прототипов, паттернов и скорингов.
- services/policy — Policy Engine (режимы, пороги, понижающие множители) для выбора действия.
- services/dataset — управление датасетом (append с защитой от дублей).
- scripts/train_* — обучение TF‑IDF и контекстного мета‑классификатора.
- config/* — конфигурация из .env и runtime‑оверрайды.

См. типы и объединённый результат анализа: `core/types.py:1`.

---

## 2. Оркестрация анализа (FilterCoordinator)

Координатор делает три вещи:
- Прогоняет быстрые фильтры Keyword и TF‑IDF.
- Формирует контекстные капсулы и считает эмбеддинги пакетно (E_msg, E_ctx, E_user).
- Обновляет историю чата и пользователя (для будущего контекста).

Код: `core/coordinator.py:1`.

Контекстные капсулы формируются в utils/textprep:
- `build_context_capsule()` — текущее сообщение + N предыдущих сообщений чата + флаги метаданных (ответ админу, форвард, автор‑админ, пост канала).
- `build_user_capsule()` — компактная история пользователя.
- `normalize_entities()` — детерминированная замена сущностей на плейсхолдеры (<URL>, <TG>, <PHONE>, <EMAIL>, <MONEY>, <AGE>). См. `utils/textprep.py:1`.

Результат координации — `AnalysisResult` (см. ниже), содержащий:
- результаты всех фильтров,
- метаданные сообщения,
- капсулы и рассчитанные эмбеддинги (если доступны).

---

## 3. Фильтры

### 3.1 KeywordFilter
- JSON‑словарь ключевых слов и regex‑паттернов; быстрый «rule‑based» скор.
- Скоры ступенчатые (0.0—0.95) в зависимости от количества совпадений.
- См. `filters/keyword.py:1`.

### 3.2 TF‑IDF Filter
- sklearn Pipeline: `TfidfVectorizer` + `MultinomialNB`.
- Обучение и сохранение модели в `models/tfidf_model.pkl`.
- Поддержка дообучения: новые примеры в `data/messages.csv` и авто‑retrain по порогу.
- См. `filters/tfidf.py:1`, обучение: `scripts/train_tfidf.py:1`.

### 3.3 Embedding Filter (контекстный)
- Пакетный провайдер эмбеддингов (Ollama) с режимами: `ollama` | `local` | `disabled`.
- Считает сразу E_msg, E_ctx и E_user с LRU‑кэшем для E_user (TTL, max size).
- Graceful degradation: если не успели получить E_ctx/E_user — продолжаем с тем, что есть.
- Параметры: таймаут, TTL кэша, модель и базовый URL задаются в .env.
- См. `filters/embedding.py:1` (провайдер `OllamaProvider` и кэш `EmbeddingCache`).

---

## 4. Типы и сводка результата (AnalysisResult)

См. `core/types.py:1`.
- `FilterResult` — имя фильтра, `score`, `confidence`, опциональные `details`.
- `MessageMetadata` — метаданные (reply_to_staff, is_forwarded, author_is_admin, is_channel_announcement и пр.).
- `EmbeddingVectors` — E_msg/E_ctx/E_user.
- `AnalysisResult` — агрегат: результаты фильтров, капсулы, векторы, плюс `meta_proba`/`meta_debug` (после мета‑классификатора). 

Легаси‑метрика `average_score` взвешивает фильтры с приоритетом на embedding, но в проде решение принимается Policy Engine по `meta_proba` (если доступна).

---

## 5. Мета‑классификатор (контекстный)

Задача — объединить всё в единую вероятность `p_spam` с прозрачной отладкой.

Артефакты:
- `models/meta_model.joblib` — LogisticRegression (или LGBM).
- `models/meta_calibrator.joblib` — калибровка вероятностей (CalibratedClassifierCV).
- `models/centroids.npz` — центроиды спама/хама.
- `models/prototypes.npz` — K‑means прототипы семейства спама/легита.
- `models/feature_spec.json` — порядок фичей.

Фичи (суммарно ~40+):
- Косинусные сходства и дельты с центроидами для E_msg/E_ctx/E_user.
- Сходства с прототипами (7 семейств спама, 4 — легит).
- Скоринги Keyword/TF‑IDF (пониженный вес как вспомогательные).
- Паттерны сырого текста: URL/PHONE/EMAIL, деньги, возраст, CTA «+», DM, удалёнка, «легально», казино, обфускация и др.
- Контекстные флаги из метаданных: ответ админу, форвард, автор‑админ, пост канала.
- Whitelist‑хиты: store/order/brand (снижают подозрительность).

API: `MetaClassifier.predict_proba(text, analysis) -> (p_spam, meta_debug)`.
Код: `services/meta_classifier.py:1`.

Обучение:
- Базовый вариант: `scripts/train_meta.py:1` — без контекстных капсул.
- Контекстный вариант: `scripts/train_meta_context.py:1` — центроиды + прототипы, Group K‑Fold, калибровка. В этом скрипте для простоты скоринги Keyword/TF‑IDF сейчас заглушки; в продакшене подставить реальные значения из фильтров.

---

## 6. Policy Engine — принятие решений

Режимы: `manual`, `semi-auto`, `auto`.
- manual: только NOTIFY при `p_spam ≥ META_NOTIFY`.
- semi-auto: NOTIFY/DELETE (KICK запрещён).
- auto: доступны все действия, пороги: `META_NOTIFY`, `META_DELETE`, `META_KICK`.

Понижающие множители (применяются до сравнения с порогами):
- is_channel_announcement → `META_DOWNWEIGHT_ANNOUNCEMENT`.
- reply_to_staff → `META_DOWNWEIGHT_REPLY_TO_STAFF`.
- whitelist_hits > 0 → `META_DOWNWEIGHT_WHITELIST`.

Degradation‑грейс: при деградации контекста (нет E_ctx) повышаем `META_NOTIFY` на +0.05, чтобы уменьшить шум. Код: `services/policy.py:1`.

Отладка решения возвращается вместе с действием (policy_mode, p_spam до/после даунвейттов, применённые множители, использованные пороги, признак деградации).

---

## 7. Интеграция с Telegram (бот и модерация)

- Входной хендлер: `bot/handlers.py:1`.
- Уведомления в чат модераторов: карточка (простая или детальная — флаг `DETAILED_DEBUG_INFO`), кнопки для ручных решений в режиме NOTIFY.
- Хранилища: `PENDING` для ожидающих решений, `SPAM_STORAGE` для `/debug`.
- Действия:
  - DELETE/KICK — удаление и бан, уведомление в чат (если `ANNOUNCE_BLOCKS=True`).
  - NOTIFY — отправка карточки модератору (без авто‑действий в чате).
- Пополнение датасета: «спам/бан» → label=1; «не спам» → label=0.
- Авто‑переобучение TF‑IDF при достижении `RETRAIN_THRESHOLD` новых примеров.

Команды (для whitelist):
- `/status`, `/retrain`, `/debug N`, `/meta_info` — мониторинг, обучение и отладка.
- `/setpolicy`, `/setthreshold`, `/setdownweight`, `/resetconfig` — runtime‑настройки через `config/runtime.py:1`.

---

## 8. Конфигурация

Основные параметры .env (см. `config/config.py:1`):
- Telegram: `BOT_TOKEN`, `MODERATOR_CHAT_ID`, `WHITELIST_USER_IDS`.
- Embeddings: `EMBEDDING_MODE` (api/ollama/local/disabled), `OLLAMA_MODEL`, `OLLAMA_BASE_URL`, таймауты и TTL кэша.
- Policy: `POLICY_MODE`, `META_NOTIFY`, `META_DELETE`, `META_KICK`, даунвейт‑множители.
- Контекст: `CONTEXT_HISTORY_N`, `CONTEXT_MAX_TOKENS`, `EMBEDDING_ENABLE_USER`.
- Пути артефактов мета‑классификатора.

Runtime‑оверрайды — через команды, сохраняются в `RuntimeConfig` (в памяти процесса).

---

## 9. Обучение и артефакты

TF‑IDF:
- Датасет `data/messages.csv` (колонки: `message`, `label`).
- Скрипт: `python scripts/train_tfidf.py` — обучение, сохранение и базовые метрики.

Мета (контекстная):
- Запуск: `python scripts/train_meta_context.py`.
- Выход: `models/meta_model.joblib`, `models/meta_calibrator.joblib`, `models/centroids.npz`, `models/prototypes.npz`, `models/feature_spec.json`, `models/train_meta_report.txt`.
- Требования: доступный Ollama c выбранной embedding‑моделью, корректный .env.

---

## 10. Производительность и надёжность

- Пакетный расчёт эмбеддингов и короткие таймауты снижают задержки.
- LRU‑кэш для E_user уменьшает нагрузку на провайдер эмбеддингов.
- Graceful degradation: отсутствие части эмбеддингов не парализует систему — Policy корректирует сенситивность.
- TF‑IDF остаётся работоспособным без эмбеддингов (базовый фолбэк).

---

## 11. К какому классу решений мы ближе

Это гибридная ML‑модерация из:
- «Лёгкие» эвристики/статистика (Keyword/TF‑IDF),
- Семантические эмбеддинги с контекстом (retrieval‑подобная часть: центроиды + прототипы),
- Лёгкий мета‑классификатор (LogReg + калибратор),
- Policy‑надстройка с контекстными даунвейтами и режимами.

Иными словами — ближе к «retrieval + shallow classifier» (иногда называют «prototype‑based moderation») с прозрачной логикой и низкой стоимостью инференса. Это не «чистый» LLM‑гейтинг, а продуманная связка фичей + эмбеддингов.

---

## 12. Роадмап апгрейда до более сильных эмбеддингов/LLM

Рекомендуем эволюционировать по ступеням, сохраняя текущую архитектуру:

1) Улучшить модель эмбеддингов
- Перейти с small‑класса на более сильные мультиязычные модели: например, e5‑large / gte‑large / bge‑m3 (в зависимости от доступности в Ollama/локально).
- Для облака — рассмотреть современные коммерческие embedding‑API с лучшими русско‑язычными метриками (учесть стоимость и приватность).
- Действия:
  - добавить бэкенд‑переключатель в `EmbeddingFilter` с graceful fallback;
  - переобучить центроиды/прототипы под новую модель;
  - обновить `feature_spec.json` и калибровку мета‑классификатора.

2) Добавить районный «перепроверщик» (reranker/cross‑encoder)
- Для сообщений в «серой зоне» (около `META_NOTIFY`):
  - прогон через компактный cross‑encoder (например, bi‑encoder эмбеддинг + лёгкий cross‑encoder как вторую ступень) — повысит precision без большой стоимости.
- Интеграция: как дополнительный шаг перед Policy для узкого процента сообщений.

3) Расширить retrieval на базе векторного хранилища
- Хранить «эталоны» спама/легита (тексты + вектора) в локальном FAISS/Qdrant.
- Вместо фиксированных прототипов — k‑NN по базе с сигналами «близости к известным семействам» (замена/дополнение к прототипам).

4) Локальный компактный LLM‑гейтинг (по желанию)
- Запускать на CPU/GPU небольшой инструктажный LLM только для спорных кейсов (few‑shot контекст + правила). Цель — объяснимость и снижение ложноположительных для «похожих на промо/магазин» сообщений.
- Важно: оставить текущую pipeline как основной быстрый слой, LLM — лишь «arbitration tier» для 5–10% пограничных случаев.

5) Улучшить обучение мета‑классификатора
- Снять заглушки: в `train_meta_context.py` подставить реальные Keyword/TF‑IDF скоринги.
- Рассмотреть LightGBM/XGBoost вместо LogReg (лучше ловит разреженные/нелинейные фичи) с калибровкой.
- Добиться стабильной ROC‑AUC/PR‑AUC, проверить калибровку (Brier score).

6) Контроль качества и безопасные эксперименты
- A/B на подвыборке чатов с уведомлениями без авто‑действий, сбор метрик.
- Логи top‑features и причин из Policy для аудит‑трейла.

Критерий готовности LLM‑уровня: когда embedding+meta перестанет давать достаточный precision/recall на наших доменных данных при приемлемых задержках, добавляем reranker/LLM в узкие места, сохраняя основную архитектуру и прозрачность.

---

## 13. Приложение: ключевые файлы

- Типы и агрегат результата: `core/types.py:1`
- Координатор фильтров и контекст: `core/coordinator.py:1`
- Keyword: `filters/keyword.py:1`
- TF‑IDF: `filters/tfidf.py:1`
- Embedding provider + кэш: `filters/embedding.py:1`
- Мета‑классификатор: `services/meta_classifier.py:1`
- Политика решений: `services/policy.py:1`
- Хендлеры/бот: `bot/handlers.py:1`, запуск: `bot/app.py:1`, `main.py:1`
- Текстовая подготовка/капсулы: `utils/textprep.py:1`
- Настройки: `config/config.py:1`, runtime‑оверрайды: `config/runtime.py:1`

---

Если нужно — могу дополнить диаграммами данных/последовательностей и чек‑листом эксплуатации (деплой, мониторинг, ротация артефактов, контроль версий моделей).
